from collections import defaultdict
from yaml import load
import os
import random
import datetime
import pathlib
import sys
import subprocess

# =============================
#
# Snakefile for single-cell RNA-seq workflow automation using Snakemake.
#
# Purpose:
# This Snakefile receives commands from the CLI wrapper 'command_line.py' and
# uses them to determine which analyses and plots to generate for the 'rule all'
# input targets. From there, Snakemake constructs the workflow DAG accordingly.
#
# Features:
# - Takes high-level commands from the CLI wrapper to drive workflow execution.
# - Dynamically generates input targets via helper functions for plotting and analysis.
# - Delegates the dependency resolution and job execution to Snakemake based on those targets.
#
# Notes:
# - The extensive variable declarations at the top are required for the .smk rule files
#   to set up wildcards and access configuration variables.
# - All configuration variables originate from a centralized config file named 'defaults.py'
#   to ensure consistent parameter usage throughout the workflow and rule files.
# - This snakefile uses a series of python functions to generate the mentioned plots, functions are called based on main argument (minimal/standard etc)
#
# =============================

from snakemake.utils import Paramspace
import pandas as pd
from snakemake.io import expand
from itertools import repeat

# Including external files by purpose
include: "rules/extra_functions.smk"

# Importing Python files
from workflow_utils.workflow_funcs import file_capture_try, initialization_of_paramspace
from workflow_utils.create_plot_functions import sample_parameter

# renamed to configDef as snakemake uses its own config if a .yaml is used.
from workflow_utils.Defaults import config as configDef

# Configuration settings - these have to be declared here too or else the rules will not have access to them. While snakefile does have its own config as mentioned
# above, its default have been merged with Defaults's configs so both snakefile and python scripts share the same settings and dont have to declare its defaults.
# functionally, these would be the same as config.get as the default python file will use the yaml if it exists.
# this script's 'native' config is based on config.yaml

option = config.get("option", "standard")  # bug where it wont accept option from Defaults.py. Alltho because sample parameter uses this in its arguments, the 
                                           # rest of the .py should have access to it too during runtime, not during unit testing so keep that in mind!
                                           
cellsnake_path=config.get('cellsnake_path','')

runid = configDef.runid
logname = configDef.logname
datafolder = configDef.datafolder
analyses_folder = configDef.analyses_folder
results_folder = configDef.results_folder
is_integrated_sample = configDef.is_integrated_sample
gene_to_plot = configDef.gene_to_plot if configDef.gene_to_plot else []

# Basic parameters
min_cells = configDef.min_cells
min_features = configDef.min_features
max_features = configDef.max_features
max_molecules = configDef.max_molecules
min_molecules = configDef.min_molecules
percent_mt = configDef.percent_mt
percent_rp = configDef.percent_rp
highly_variable_features = configDef.highly_variable_features
variable_selection_method = configDef.variable_selection_method
doublet_filter = "--doublet.filter" if configDef.doublet_filter in [True, "TRUE", "True", "T"] and not is_integrated_sample else ""
metadata = configDef.metadata
metadata_column = configDef.metadata_column
keywords = configDef.keywords
exact = "--exact" if configDef.exact in [True, "TRUE", "True", "T"] else ""
subset_file = configDef.subset_file
subset_column = configDef.subset_column
min_percentage_to_plot = configDef.min_percentage_to_plot
mapping = configDef.mapping
organism = configDef.organism
species = configDef.species

# Automatic MT filtering
grid_search = config.get("grid_search", False)

# Clustering and normalization parameters
normalization_method = configDef.normalization_method
scale_factor = configDef.scale_factor
resolution = configDef.resolution

umap_plot = "--umap" if config.get("umap_plot", True) in [True, "TRUE", "True", "T"] else ""  #changing these 3 throws more warning, investigate further.
tsne_plot = "--tsne" if config.get("tsne_plot", True) in [True, "TRUE", "True", "T"] else ""
show_labels = "--labels" if config.get("show_labels", True) in [True, "TRUE", "True", "T"] else ""

# Differential expression parameters
logfc_threshold = configDef.logfc_threshold
test_use = configDef.test_use
marker_plots_per_cluster_n = configDef.marker_plots_per_cluster_n
identity_to_analysis = configDef.identity_to_analysis
selected_gene_file = configDef.selected_gene_file

#GSEA
gsea_file = configDef.gsea_file if configDef.gsea_file else cellsnake_path + "workflow/bundle/c2.cgp.v2022.1.Hs.symbols.gmt"
gsea_group = configDef.gsea_group
integration_id = configDef.integration_id
celltypist_model = configDef.celltypist_model
singler_ref = configDef.singler_ref
singler_granulation = configDef.singler_granulation

# Kraken DB
kraken_db_folder = configDef.kraken_db_folder
prekraken_db_folder = configDef.prekraken_db_folder
taxa = configDef.taxa
microbiome_min_cells = configDef.microbiome_min_cells
microbiome_min_features = configDef.microbiome_min_features
confidence = configDef.confidence
min_hit_groups = configDef.min_hit_groups
kraken_extra_files = True if configDef.kraken_extra_files in [True, "TRUE", "True", "T"] else False
bowtie_database_prefix = configDef.bowtie_database_prefix
complexity = configDef.complexity
reduction = configDef.reduction
dims = configDef.dims

errHandle = configDef.errHandle

files = file_capture_try(datafolder)
par_df = initialization_of_paramspace("params.tsv",{"percent_mt":[percent_mt],"resolution":[resolution]})
paramspace=Paramspace(par_df)

# samples = ["10X_17_029"] # debugging purpose.

# Decide which rules to include based on 'option' and test mode
if option == "test":
    # Get the test mode from config
    mode = config.get("test_mode", "")  # Assuming the mode is passed through --config test_mode=<mode>

    # Include the rules file that contains the tests
    include: "rules/seuratTest.smk"

    if mode == "all":
        rule all:
            input:
                f"{cellsnake_path}workflow/tests/testData/results/test_complete.txt"
    elif mode == "cover":
        rule all:
            input:
                f"{cellsnake_path}scrna/workflow/tests/testData/test_coverage.csv"
    else:
        print(f"Unknown test mode '{mode}', please use 'all' or 'cover'.")
        exit(1)  # Exit if the mode is not recognized


elif option in ["integration","integrate"]:
    #integration_files = list(pathlib.Path("analyses/processed/").rglob("*.rds"))
    a,b,c=cellsnake_glob_wildcards("analyses/processed/percent_mt~{a}/resolution~{b}/{c}.rds")
    integration_files=expand("analyses/processed/percent_mt~{a}/resolution~{b}/{c}.rds",zip,a=a,b=b,c=c)

    total_samples_to_merge=len(set(c))
    total_rds_files=len(list(zip(a,b,c)))
    total_mt_samples=len(set(zip(a,c)))
    
    #print(total_samples_to_merge)
    #print(total_mt_samples)
    if total_samples_to_merge > 1: # there are at least two samples
        if total_rds_files > total_samples_to_merge:

            integration_files=[]
            if total_mt_samples == total_samples_to_merge:
                print("I detected more than one RDS file per sample, I will select one of them to merge...")
                for i in set(c):
                    integration_files.append(list(pathlib.Path("analyses/processed/").rglob(i + ".rds"))[0])
            else:
                print("There are identical samples with different MT content, I am not sure how to merge them, better to remove some RDS files manually...")
                print(expand("analyses/processed/percent_mt~{a}/resolution~{b}/{c}.rds",zip,a=a,b=b,c=c))
     
    #print(integration_files)
    include: "rules/integration.smk"
    rule all:
        input:
             "analyses_integrated/seurat/" + integration_id + ".rds" if len(integration_files) > 1 else []
    
    if not any(b in ["--dry-run", "--dryrun", "-n"] for b in sys.argv):
        write_main_log([str(i) for i in integration_files])

elif option in ["minimal","standard","clustree","clusteringTree","advanced"] and files:
    include: "rules/seurat.smk"
    include: "rules/microbiome.smk"
    rule all:
        input:
            sample_parameter(paramspace,files, option)

elif option in ["subset"] and files:
    include: "rules/subset.smk"
    rule all:
        input:
            "dataoutput/" + subset_file + ".rds"


else:
    print("Please select a correct option or no files detected...")
    pass
